{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/data_int.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18108/4186123418.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ml_int\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# l=[\"a\",\"b\",\"c\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/data_int.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml_int\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/data_int.txt'"
     ]
    }
   ],
   "source": [
    "# list of integers \n",
    "l_int = [x for x in range(100)]\n",
    "# l=[\"a\",\"b\",\"c\"]\n",
    "file = open(\"data/data_int.txt\",\"w\")\n",
    "\n",
    "for i in l_int:\n",
    "    file.write(str(i)+\"\\n\")\n",
    "file.close()\n",
    "\n",
    "\n",
    "!type data\\data_int.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a matrix of 5x5 matrix\n",
    " \n",
    "val = np.arange(25,  dtype=float).reshape(5,5)\n",
    "# np.array(val,dtype=float)\n",
    "print(val)\n",
    "\n",
    "file_float= open(\"data/data_float.txt\",\"w\")\n",
    "\n",
    "# for elment in file_float:\n",
    "#      np.savetxt(file_float, elment, fmt='%.2f')\n",
    "# file_float.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data/data_float.txt\",val, fmt=\"%0.3f\")\n",
    "!type data\\data_float.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concerting text to CSV\n",
    "\n",
    "# with open(\"data/data_float.txt\", 'r') as infile, open(\"data/data_float.csv\", 'w') as outfile:\n",
    "#         stripped = (line.strip() for line in infile)\n",
    "#         lines = (line.split(\",\") for line in stripped if line)\n",
    "#         writer = csv.writer(outfile)\n",
    "#         writer.writerows(lines)\n",
    "# load_txt = pd.read_fwf(\"data/data_float.txt\",delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "headl =['A']\n",
    "read_file = pd.read_fwf (r'data/data_int.txt', delim_whitespace=True, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing and converting float text file into csv file\n",
    "\n",
    "# read_float = pd.read_table('data/data_float.txt',sep=' ',names=['A','B','C','D','E'])\n",
    "# read_float.to_csv('data/data_float.csv',index=None)\n",
    "\n",
    "!type data\\data_float.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing data from pandas dataframe\n",
    "\n",
    "df =  pd.read_csv('data/data_float.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the json file\n",
    "df =  pd.read_json('data/user_data.json')\n",
    "\n",
    "credit_A = df[df['CreditCardType']=='American Express']\n",
    "print(credit_A)\n",
    "# total_number = credit.shape[0]\n",
    "\n",
    "credit.to_csv('data/American_Express.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading directly from URL\n",
    "# import dropbox as DBX\n",
    "import io\n",
    "import dropbox\n",
    "\n",
    "import urllib.request\n",
    "url = 'https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv?dl=1'\n",
    "u = urllib.request.urlopen(url)\n",
    "data = u.read()\n",
    "u.close()\n",
    "\n",
    "with open('data/mushrooms_categorized.csv', \"wb\") as f :\n",
    "    f.write(data)\n",
    "\n",
    "\n",
    "\n",
    "# url = 'https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv?dl=1'\n",
    "# with urllib.request.urlopen(url) as data_file:\n",
    "# #     print (data_file.read(300))\n",
    "#     for line in data_file:\n",
    "# #         print(line)\n",
    "        \n",
    "        \n",
    "# grouping the data and taking the average\n",
    "cat_avg =  pd.read_csv('data/mushrooms_categorized.csv')\n",
    "cat_j = cat_avg.groupby('class').mean()\n",
    "\n",
    "# print(cat_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to json file\n",
    "import json\n",
    "cat_j.to_json('data/class_cat.json')\n",
    "\n",
    "# !type data\\class_cat.json\n",
    "\n",
    "js=pd.read_json('data/class_cat.json')\n",
    "js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !type data\\credit_card.dat\n",
    "ind=1\n",
    "char_l = 6\n",
    "with open('data\\credit_card.dat') as file:\n",
    "    for card in file:\n",
    "        code=[]\n",
    "        for j in range(0,len(card),char_l):\n",
    "            code.append(chr(int(card[j:j+char_l],2)))\n",
    "        if ind<51:\n",
    "            print(ind,\"\".join(code))\n",
    "        ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.dropbox.com/s/aamg1apjhclecka/regression_generated.csv?dl=1'\n",
    "# file = urllib.request.urlopen(url)\n",
    "pl = pd.read_csv(url) \n",
    "# pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting the features against labels\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pl.plot.scatter(x='features_1',y='features_2',c='label',colormap='viridis')\n",
    "pl.plot.scatter(x='features_2',y='features_3',c='label',colormap='gist_rainbow')\n",
    "pl.plot.scatter(x='features_1',y='features_3',c='label',colormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/data_format.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, ``pack'' the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_OSEMN.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
